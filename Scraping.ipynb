{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65193f-9264-4584-a0dc-4ab1f88d6d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa6b0a3-064f-4de6-a343-1fe7b592f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5aadd29-a810-4f1a-979c-aef6d78ee449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromeDriver \n",
    "chrome_driver_path = \"D:/chromedriver/chromedriver.exe\"\n",
    "chrome_options = Options()\n",
    "chrome_options.page_load_strategy = 'eager'  # Load pages faster\n",
    "service = Service(chrome_driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4e8f176-c05b-4278-a25d-69969ddfd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page: https://www.zameen.com/Flats_Apartments/Peshawar-17-1.html\n",
      "page# 1 completed..,.\n",
      "Scraping completed .......\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def convert_relative_time_to_date(relative_time):\n",
    "    current_time = datetime.now()\n",
    "    if \"minute\" in relative_time:\n",
    "        minutes = int(relative_time.split()[0])\n",
    "        return current_time - timedelta(minutes=minutes)\n",
    "    elif \"hour\" in relative_time:\n",
    "        hours = int(relative_time.split()[0])\n",
    "        return current_time - timedelta(hours=hours)\n",
    "    elif \"day\" in relative_time:\n",
    "        days = int(relative_time.split()[0])\n",
    "        return current_time - timedelta(days=days)\n",
    "    elif \"week\" in relative_time:\n",
    "        weeks = int(relative_time.split()[0])\n",
    "        return current_time - timedelta(weeks=weeks)\n",
    "    else:\n",
    "        return current_time  # Default to now if parsing fails\n",
    "\n",
    "\n",
    "with open(\"zameen_data.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)                                                 \n",
    "    # Write the header                                                        \n",
    "    writer.writerow([\"Title\", \"Price\", \"Location\", \"Beds\", \"Area\", \"Baths\", \"Agent\", \"Date\", \"Company\"])\n",
    "    \n",
    "    # Loop through multiple pages (example: limit to 4 pages)\n",
    "    for page_number in range(1, 4):  \n",
    "\n",
    "        titles, prices, locations, beds, area, baths, agents, dates, companies = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "        url = f\"https://www.zameen.com/Flats_Apartments/Peshawar-17-{page_number}.html\"\n",
    "        print(f\"Scraping page: {url}\")\n",
    "        \n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "\n",
    "        WebDriverWait(driver, 7).until(EC.presence_of_element_located((By.CLASS_NAME, \"a37d52f0\")))\n",
    "\n",
    "        # Get the page source and parse it with BeautifulSoup\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        \n",
    "        listings = soup.find_all(\"li\", role=\"article\", class_=\"a37d52f0\")\n",
    "\n",
    "     \n",
    "        for i in range(0, len(listings), 4):\n",
    "            tabs_to_open = []\n",
    "\n",
    "            for j in range(4):\n",
    "                if i + j >= len(listings):\n",
    "                    break\n",
    "                listing = listings[i + j]\n",
    "\n",
    "                # Extract details directly from the main page\n",
    "                try:\n",
    "                    title = listing.find(\"h2\", class_=\"_36dfb99f\").text.strip()\n",
    "                    property_link = listing.find(\"a\", href=True)[\"href\"]  # Extract the property link\n",
    "                    titles.append(title)\n",
    "                except:\n",
    "                    titles.append(\" \")\n",
    "\n",
    "              \n",
    "                try:\n",
    "                    price = listing.find(\"span\", class_=\"dc381b54\").text.strip()\n",
    "                except:\n",
    "                    price = \" \"\n",
    "                prices.append(price)\n",
    "\n",
    "                \n",
    "                try:\n",
    "                    location = listing.find(\"div\", class_=\"db1aca2f\").text.strip()\n",
    "                except:\n",
    "                    location = \" \"\n",
    "                locations.append(location)\n",
    "\n",
    "               \n",
    "                try:\n",
    "                    bed = listing.find(\"span\", class_=\"_6d9b9b83\", attrs={\"aria-label\": \"Beds\"}).text.strip()\n",
    "                except:\n",
    "                    bed = \" \"\n",
    "                beds.append(bed)\n",
    "\n",
    "                \n",
    "                try:\n",
    "                    area_value = listing.find(\"span\", class_=\"_6d9b9b83\", attrs={\"aria-label\": \"Area\"}).text.strip()\n",
    "                except:\n",
    "                    area_value = \" \"\n",
    "                area.append(area_value)\n",
    "\n",
    "              \n",
    "                try:\n",
    "                    bath = listing.find(\"span\", class_=\"_6d9b9b83\", attrs={\"aria-label\": \"Baths\"}).text.strip()\n",
    "                except:\n",
    "                    bath = \" \"\n",
    "                baths.append(bath)\n",
    "\n",
    "                \n",
    "                if property_link:\n",
    "                    full_url = 'https://www.zameen.com' + property_link\n",
    "                    driver.execute_script(\"window.open('\" + full_url + \"', '_blank');\")\n",
    "                    tabs_to_open.append(driver.window_handles[-1])\n",
    "\n",
    "           \n",
    "            for tab_handle in tabs_to_open:\n",
    "                driver.switch_to.window(tab_handle)\n",
    "                try:\n",
    "\n",
    "                    WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.CLASS_NAME, \"d10ba6ac\")))\n",
    "                    agent_name = driver.find_element(By.CLASS_NAME, \"d10ba6ac\").text.strip()\n",
    "                except:\n",
    "                    agent_name = \"N/A\"\n",
    "                agents.append(agent_name)\n",
    "\n",
    "            \n",
    "                try:\n",
    "                    creation_relative_time = WebDriverWait(driver, 5).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, \"//span[@aria-label='Creation date']\"))\n",
    "                    ).text.strip()\n",
    "\n",
    "                    creation_date = convert_relative_time_to_date(creation_relative_time)\n",
    "                    dates.append(creation_date.strftime('%Y-%m-%d %H:%M:%S'))  # Format the date\n",
    "                except:\n",
    "                    dates.append(\"N/A\")\n",
    "\n",
    "               \n",
    "                try:\n",
    "                    WebDriverWait(driver, 2).until(EC.presence_of_element_located((By.CLASS_NAME, \"_0a8efec2\")))\n",
    "                    company_name = driver.find_element(By.CLASS_NAME, \"_0a8efec2\").text.strip()\n",
    "                except:\n",
    "                    company_name = \"N/A\"\n",
    "                companies.append(company_name)\n",
    "\n",
    "          \n",
    "            for tab_handle in tabs_to_open:\n",
    "                driver.switch_to.window(tab_handle)       #   *Close the 4 tabs after data extraction *\n",
    "                driver.close()\n",
    "\n",
    "          \n",
    "            driver.switch_to.window(driver.window_handles[0])        # Close tabs after data extraction\n",
    " \n",
    "        \n",
    "        for i in range(len(titles)):    # Write the data for this page to the CSV file\n",
    "            writer.writerow([titles[i], prices[i], locations[i], beds[i], area[i], baths[i], agents[i], dates[i], companies[i]])\n",
    "\n",
    "        print(f\"page# {page_number} completed..,.\")\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(\"Scraping completed .......\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79765e-cf0e-4fcc-b023-3f475e13f40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
